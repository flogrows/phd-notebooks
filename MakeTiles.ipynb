{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import xarray as xr\n",
    "import yaml\n",
    "\n",
    "import imageio.v3 as iio\n",
    "\n",
    "from convml_tt.data.dataset import TRIPLET_TILE_FILENAME_FORMAT, TRIPLET_TILE_IDENTIFIER_FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a set of tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working folder\n",
    "folder = \"AquaHkmLabSea2022b\"\n",
    "filepath = \"/home/eefjg/OneDrive/Leeds/PhD/Data/MODIS/\"+folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make tiles from png images (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image files\n",
    "filenames = glob(filepath+\"/sliced/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21414/1237422528.py:5: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_nx = tile_ny = 256\n",
    "img_tiles = []\n",
    "\n",
    "for file in filenames:\n",
    "    img = imageio.imread(file)\n",
    "    img = img[:,:,:3] # last term gets rid of alpha channel\n",
    "    ny, nx, _ = img.shape\n",
    "    for i in range(0, nx-tile_nx, 64):\n",
    "        for j in range(0, ny-tile_ny, 64):\n",
    "            img_tile = img[j:j+tile_ny, i:i+tile_nx, :]\n",
    "            img_tiles.append(img_tile)\n",
    "\n",
    "len(img_tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Singlet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_path_dataset = Path(filepath+\"/tiles\")\n",
    "fp_path_dataset.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10224/10224.0 [02:23<00:00, 71.30it/s]\n"
     ]
    }
   ],
   "source": [
    "stride = 5 # What fraction of the tiles to keep?\n",
    "n = len(img_tiles)\n",
    "for n, i in enumerate(tqdm(range(n)[::stride], total=len(img_tiles)/stride)):\n",
    "    fn = TRIPLET_TILE_FILENAME_FORMAT.format(triplet_id=n, tile_type=\"anchor\")\n",
    "    fp_tile = fp_path_dataset / fn\n",
    "    img_tile = img_tiles[i]\n",
    "    imageio.imwrite(uri=fp_tile, im=img_tile, format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Triplet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_path_dataset = Path(filepath+\"/triplets\")\n",
    "fp_path_dataset.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10224/10224.0 [07:04<00:00, 24.08it/s]\n"
     ]
    }
   ],
   "source": [
    "stride = 5 # What fraction of the tiles to keep?\n",
    "n = len(img_tiles)-2\n",
    "for n, i in enumerate(tqdm(range(n)[::stride], total=len(img_tiles)/stride)):\n",
    "    #anchor\n",
    "    fn = TRIPLET_TILE_FILENAME_FORMAT.format(triplet_id=n, tile_type=\"anchor\")\n",
    "    fp_tile = fp_path_dataset / fn\n",
    "    img_tile = img_tiles[i]\n",
    "    imageio.imwrite(uri=fp_tile, im=img_tile, format=\"png\")\n",
    "    #neighbour - overlap half of the tile\n",
    "    fn = TRIPLET_TILE_FILENAME_FORMAT.format(triplet_id=n, tile_type=\"neighbor\")\n",
    "    fp_tile = fp_path_dataset / fn\n",
    "    img_tile = img_tiles[i+2] # not totally satisfactory, tiles from edges may not actually be neighbours, also randomise direction?\n",
    "    imageio.imwrite(uri=fp_tile, im=img_tile, format=\"png\")\n",
    "    #distant - sampled from random image (how to ensure not from same image?)\n",
    "    fn = TRIPLET_TILE_FILENAME_FORMAT.format(triplet_id=n, tile_type=\"distant\")\n",
    "    fp_tile = fp_path_dataset / fn\n",
    "    img_tile = img_tiles[random.randint(0, len(img_tiles)-1)]\n",
    "    imageio.imwrite(uri=fp_tile, im=img_tile, format=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tiles using functions from convml-data\n",
    "Now including metadata!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from convml_data/pipeline/triplets.py\n",
    "# This divides the scenes into sets for train, study etc, (don't really need it yet)\n",
    "# N_triplets should be a dictionary e.g. {train: 10, study: 2} - can just use study for now\n",
    "\n",
    "def split_scene_ids(scene_ids, N_triplets): \n",
    "    scene_collections = {}\n",
    "    \n",
    "    # split all scene IDs randomly so that for each collection in\n",
    "    # `N_triplets` the fraction of scenes allocated equals the fraction\n",
    "    # of triplets in the collection\n",
    "    N_scenes_total = len(scene_ids)\n",
    "    N_triplets_total = sum(N_triplets.values())\n",
    "    scene_ids_shuffled = np.random.permutation(scene_ids)\n",
    "\n",
    "    def split_list(arr, idx):\n",
    "        return arr[:idx], arr[idx:]\n",
    "\n",
    "    for i, (collection_name, N_triplets_collection) in enumerate(\n",
    "        N_triplets.items()\n",
    "    ):\n",
    "        if i <= N_scenes_total - 1:\n",
    "            f = N_triplets_collection / N_triplets_total\n",
    "            N_scenes_collection = int(f * N_scenes_total)\n",
    "        else:\n",
    "            N_scenes_collection = len(scene_ids_shuffled)\n",
    "\n",
    "        collection_scene_ids, scene_ids_shuffled = split_list(\n",
    "            scene_ids_shuffled, N_scenes_collection\n",
    "        )\n",
    "        scene_collections[collection_name] = collection_scene_ids\n",
    "\n",
    "    return scene_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work out which scenes to take the anchor and distant tiles from by \n",
    "# picking two random scenes for each tile id.\n",
    "\n",
    "def tile_scene_splits(scene_ids, scene_ids_by_collection, N_triplets):\n",
    "    tiles_per_scene = {}\n",
    "\n",
    "    for scene_id in scene_ids:\n",
    "        tiles_per_scene[scene_id] = []\n",
    "\n",
    "    for triplet_collection, n_triplets in N_triplets.items():\n",
    "        collection_scene_ids = scene_ids_by_collection[triplet_collection]\n",
    "        for n in range(n_triplets):\n",
    "            # pick two random scene IDs, ensuring that they are different\n",
    "            scene_id_anchor, scene_id_distant = np.random.choice(\n",
    "                collection_scene_ids, size=2, replace=False # replace=False so same scene not picked twice\n",
    "            )\n",
    "\n",
    "            scene_ids = [scene_id_anchor, scene_id_distant]\n",
    "\n",
    "            for scene_id, is_distant in zip(scene_ids, [False, True]):\n",
    "                tiles_per_scene[scene_id].append(\n",
    "                    dict(\n",
    "                        triplet_id=n,\n",
    "                        is_distant=is_distant,\n",
    "                        triplet_collection=triplet_collection,\n",
    "                            )\n",
    "                        )\n",
    "    return tiles_per_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: work out tile locations\n",
    "# adapted from convml_data/sampling/triplets.py\n",
    "\n",
    "def generate_randomly_located_tile(slice_shape, tile_size, rng=None):\n",
    "    \"\"\"\n",
    "    Generate a tile location for a specific `tile_size` that fits inside a slice\n",
    "    \"\"\"\n",
    "    \n",
    "    margin = tile_size * 0.6\n",
    "    d_xmin = 0 + margin\n",
    "    d_xmax = slice_shape[1] - margin\n",
    "    d_ymin = 0 + margin\n",
    "    d_ymax = slice_shape[0] - margin\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(rng)\n",
    "\n",
    "    x_t = (d_xmin + (d_xmax - d_xmin) * rng.uniform())\n",
    "    y_t = (d_ymin + (d_ymax - d_ymin) * rng.uniform())\n",
    "\n",
    "    return x_t, y_t\n",
    "\n",
    "\n",
    "# generate a tile location randomly offset from another tile location\n",
    "# i.e. the neighbour tile location\n",
    "\n",
    "def generate_tile_domain_with_peturbed_location(\n",
    "    slice_shape, tile_loc, tile_size, distance_size_scaling=0.5, rng=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a tile location for a specific `tile_size` that fits inside a slice,\n",
    "    perturbed from a given `tile_loc` location\n",
    "    distance_size_scaling = distance of neighbour centre from anchor centre in units of tile size\n",
    "    \"\"\"\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(rng)\n",
    "\n",
    "    theta = 2 * np.pi * rng.uniform()\n",
    "    r = distance_size_scaling * tile_size # offset distance\n",
    "    dlx = r * np.cos(theta)\n",
    "    dly = r * np.sin(theta)\n",
    "\n",
    "    x_t = (tile_loc[0] + dlx)\n",
    "    y_t = (tile_loc[1] + dly)\n",
    "\n",
    "    margin = tile_size * 0.6\n",
    "    if x_t < margin or x_t > (slice_shape[1] - margin) \\\n",
    "        or y_t < margin or y_t > (slice_shape[0] - margin):\n",
    "        return generate_tile_domain_with_peturbed_location(\n",
    "            slice_shape=slice_shape,\n",
    "            tile_loc=tile_loc,\n",
    "            tile_size=tile_size,\n",
    "            distance_size_scaling=distance_size_scaling,\n",
    "            rng=rng,\n",
    "        )\n",
    "    else: \n",
    "        return x_t, y_t\n",
    "\n",
    "\n",
    "def generate_triplet_location(slice_shape, tile_size, neigh_dist_scaling=0.5, rng=None):\n",
    "    # Do you really need this when you don't sample anchor and distant from the same scene?\n",
    "    \"\"\"\n",
    "    Generate a set of (x,y)-positions (a list of three specifically)\n",
    "    representing the \"anchor\", \"neighbor\" and \"distant\" tile locations\n",
    "    \"\"\"\n",
    "    anchor_tile_domain = generate_randomly_located_tile(\n",
    "        slice_shape=slice_shape, tile_size=tile_size, rng=rng\n",
    "    )\n",
    "\n",
    "    neighbor_tile_domain = generate_tile_domain_with_peturbed_location(\n",
    "        slice_shape=slice_shape,\n",
    "        tile_loc=anchor_tile_domain,\n",
    "        tile_size=tile_size,\n",
    "        distance_size_scaling=neigh_dist_scaling,\n",
    "        rng=rng,\n",
    "    )\n",
    "    distant_tile_domain = generate_randomly_located_tile(\n",
    "        slice_shape=slice_shape, tile_size=tile_size, rng=rng\n",
    "    )\n",
    "\n",
    "    return [anchor_tile_domain, neighbor_tile_domain, distant_tile_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take tile_per_scene yaml, split by scene, then for each scene, generate tile x and y\n",
    "\n",
    "def generate_tile_locations(tiles_per_scene, slice_shape, tile_size, neigh_dist_scaling=0.5, rng=None):\n",
    "    ''' write triplet locations to yaml file for each scene\n",
    "        tiles_per_scene: dictionary of scene IDs and tile IDs\n",
    "        slice_shape: shape of the slice\n",
    "        tile_size: size of the tile\n",
    "        neigh_dist_scaling: distance of neighbour centre from anchor centre in units of tile size\n",
    "        rng: random number generator\n",
    "    '''\n",
    "\n",
    "    scene_tile_locations = {}\n",
    "    for scene_id, tiles in tiles_per_scene.items():\n",
    "        tile_locations = []\n",
    "        for tile in tiles:\n",
    "            triplet_id = tile[\"triplet_id\"]\n",
    "            triplet_collection = tile[\"triplet_collection\"]\n",
    "            is_distant = tile[\"is_distant\"]\n",
    "\n",
    "            if is_distant:\n",
    "                x_d, y_d = generate_randomly_located_tile(slice_shape, tile_size, rng=None)\n",
    "                distant_meta = dict(\n",
    "                    loc=dict(x_c=x_d, y_c=y_d),\n",
    "                    tile_type=\"distant\",\n",
    "                    triplet_id=triplet_id,\n",
    "                    triplet_collection=triplet_collection,\n",
    "                )\n",
    "                tile_locations.append(distant_meta)\n",
    "\n",
    "            else:\n",
    "                x_a, y_a = generate_randomly_located_tile(slice_shape, tile_size, rng=None)\n",
    "                anchor_meta = dict(\n",
    "                    loc=dict(x_c=x_a, y_c=y_a),\n",
    "                    tile_type=\"anchor\",\n",
    "                    triplet_id=triplet_id,\n",
    "                    triplet_collection=triplet_collection,\n",
    "                )\n",
    "                tile_locations.append(anchor_meta)\n",
    "\n",
    "                x_n, y_n = generate_tile_domain_with_peturbed_location(\n",
    "                    slice_shape=slice_shape,\n",
    "                    tile_loc=[x_a, y_a],\n",
    "                    tile_size=tile_size,\n",
    "                    distance_size_scaling=neigh_dist_scaling,\n",
    "                    rng=None,\n",
    "                )\n",
    "                neighbor_meta = dict(\n",
    "                    loc=dict(x_c=float(x_n), y_c=float(y_n)),\n",
    "                    tile_type=\"neighbor\",\n",
    "                    triplet_id=triplet_id,\n",
    "                    triplet_collection=triplet_collection,\n",
    "                )\n",
    "                tile_locations.append(neighbor_meta)\n",
    "\n",
    "        with open(filepath + \"/meta/\" + f\"{scene_id}_tile_locations.yaml\", \"w\") as f:\n",
    "            yaml.dump(tile_locations, f)\n",
    "        scene_tile_locations[scene_id] = tile_locations\n",
    "    return scene_tile_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: generate image and yaml file for each tile\n",
    "\n",
    "def generate_all_tiles(datapath, savepath, scene_tile_locations, tile_size):\n",
    "    ''' write triplet tiles to png and yaml file for each scene\n",
    "        scene_tile_locations: dictionary of scene IDs and tile locations\n",
    "        scene_id: scene ID\n",
    "        slice_shape: shape of the slice\n",
    "        tile_size: size of the tile\n",
    "    '''\n",
    "\n",
    "    for scene_id, tiles in tqdm(scene_tile_locations.items()):\n",
    "        \n",
    "        data = datapath + scene_id + \".nc\"\n",
    "        with xr.open_dataset(data) as scene_ds:\n",
    "            scene_ds.load()\n",
    "            \n",
    "            for tile in tiles:\n",
    "                triplet_id = tile[\"triplet_id\"]\n",
    "                triplet_collection = tile[\"triplet_collection\"]\n",
    "                tile_type = tile[\"tile_type\"]\n",
    "                x_c = tile[\"loc\"][\"x_c\"]\n",
    "                y_c = tile[\"loc\"][\"y_c\"]\n",
    "                    \n",
    "                tile_identifier = TRIPLET_TILE_IDENTIFIER_FORMAT.format(triplet_id=triplet_id, \n",
    "                                                                        tile_type=tile_type)\n",
    "                fn_data = f\"{tile_identifier}.nc\"\n",
    "                fn_image = f\"{tile_identifier}.png\"\n",
    "                fn_meta = f\"{tile_identifier}.yml\"\n",
    "                \n",
    "                # crop nc file to tile and save\n",
    "\n",
    "                tile_ds = scene_ds.sel(x=slice(int(x_c-tile_size/2), int(x_c+tile_size/2)), \n",
    "                                    y=slice(int(y_c-tile_size/2), int(y_c+tile_size/2)))\n",
    "                \n",
    "                tile_ds.to_netcdf(savepath + fn_data)\n",
    "\n",
    "                # save png of rgb\n",
    "            \n",
    "                img_data = iio.imread(datapath + scene_id + \".png\")\n",
    "                img_tile = img_data[slice(int(y_c-tile_size/2), int(y_c+tile_size/2)), \n",
    "                            slice(int(x_c-tile_size/2), int(x_c+tile_size/2))]\n",
    "\n",
    "                iio.imwrite(uri=(savepath + fn_image), image=img_tile, format=\"png\")\n",
    "\n",
    "                # save yaml file with metadata\n",
    "\n",
    "                tile_meta = dict(\n",
    "                triplet_id=triplet_id,\n",
    "                triplet_collection=triplet_collection,\n",
    "                tile_type=tile_type,\n",
    "                loc=dict(x_c=x_c, \n",
    "                        y_c=y_c,\n",
    "                        central_latitude = float(scene_ds.latitude.sel(x=int(x_c), y=int(y_c)).values),    \n",
    "                        central_longitude = float(scene_ds.longitude.sel(x=int(x_c), y=int(y_c)).values)), \n",
    "                        scene_id=scene_id,\n",
    "                        land_fraction = 1 - float(tile_ds.watermask.mean())\n",
    "            )\n",
    "                with open(savepath + fn_meta, \"w\") as f:\n",
    "                    yaml.dump(tile_meta, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To revisit:  \n",
    "- Can I parallelise tile generation somehow?\n",
    "- if need different collections i.e. train/study need to separate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filepath+\"/meta/scene_ids.yaml\", \"r\") as f:\n",
    "    scene_ids = yaml.safe_load(f)\n",
    "\n",
    "len(scene_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_triplets = {\"study\": 10000}\n",
    "scene_ids_by_collection = split_scene_ids(list(scene_ids.keys()), N_triplets)\n",
    "tiles_per_scene = tile_scene_splits(scene_ids, scene_ids_by_collection, N_triplets)\n",
    "\n",
    "# write tiles_per_scene to yaml\n",
    "with open(filepath+\"/meta/tile_scene_splits.yaml\", \"w\") as f:\n",
    "    yaml.dump(tiles_per_scene, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_shape = (4060, 1024) # y, x\n",
    "tile_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene_tile_locations = generate_tile_locations(\n",
    "    tiles_per_scene, slice_shape, tile_size, neigh_dist_scaling=0.5, rng=None)\n",
    "\n",
    "# write scene_tile_locations to yaml\n",
    "with open(filepath+\"/meta/all_scene_tile_locations.yaml\", \"w\") as f:\n",
    "    yaml.dump(scene_tile_locations, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If scene locations already generated then run from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256\n",
    "\n",
    "with open(filepath+\"/meta/all_scene_tile_locations.yaml\", \"r\") as f:\n",
    "    scene_tile_locations = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [1:10:31<00:00, 59.59s/it]\n"
     ]
    }
   ],
   "source": [
    "datapath = filepath + \"/sliced/\"\n",
    "savepath = filepath + \"/triplets/\"\n",
    "\n",
    "path = Path(savepath)\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "generate_all_tiles(datapath, savepath, scene_tile_locations, tile_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convml-tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
